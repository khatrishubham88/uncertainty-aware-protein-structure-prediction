{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from readData_from_TFRec import widen_seq, parse_dataset, create_protein_batches\n",
    "from utils import expand_dim, calc_pairwise_distances, to_distogram, load_npy_binary, output_to_distancemaps\n",
    "from utils import pad_mask, pad_primary, pad_tertiary, masked_categorical_cross_entropy\n",
    "import glob\n",
    "import math\n",
    "import tensorflow.keras.backend as K\n",
    "from readData_from_TFRec import parse_tfexample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_transform(primary, evolutionary, tertiary, tertiary_mask, stride, padding_value=-1, minimum_bin_val=2, \n",
    "                        maximum_bin_val=22, num_bins=64):\n",
    "    \n",
    "    # correcting the datatype to avoid errors\n",
    "    stride = int(stride)\n",
    "    padding_value = float(padding_value)\n",
    "    minimum_bin_val = float(minimum_bin_val)\n",
    "    maximum_bin_val = float(maximum_bin_val)\n",
    "    num_bins = int(num_bins)\n",
    "    \n",
    "    # detecting the number of crops\n",
    "    crops_per_seq = primary.shape[0] // stride\n",
    "    if (primary.shape[0] % stride > 0) and (crops_per_seq > 0):\n",
    "        crops_per_seq += 1\n",
    "    total_crops = crops_per_seq * crops_per_seq\n",
    "    \n",
    "    # compute padding necessary for this protein\n",
    "    # Find the number of padding elements\n",
    "    num_padding = math.ceil(primary.shape[0]/stride)*stride - primary.shape[0] \n",
    "    # pad on left and bottom\n",
    "    padding = tf.constant([[0, num_padding]])\n",
    "    \n",
    "    # primary transformation\n",
    "    # compute the rank of tensor to apply padding\n",
    "    primary_rank = tf.rank(primary).numpy()\n",
    "    primary_padding = tf.repeat(padding, primary_rank, axis=0)\n",
    "    primary = tf.pad(primary, primary_padding, constant_values=tf.cast(padding_value, primary.dtype))\n",
    "    # widen primary sequence to convert it to 2D\n",
    "    primary = widen_seq(primary)\n",
    "    # cast it to float for the model\n",
    "    primary = K.cast_to_floatx(primary)\n",
    "    \n",
    "    # tertiary trnsformation\n",
    "    tertiary = calc_pairwise_distances(tertiary)\n",
    "    # pad on left and bottom\n",
    "    tertiary_rank = tf.rank(tertiary).numpy()\n",
    "    tertiary_padding = tf.repeat(padding, tertiary_rank, axis=0)\n",
    "    tertiary = tf.pad(tertiary, tertiary_padding, constant_values=tf.cast(padding_value, tertiary.dtype))\n",
    "    \n",
    "    # mask transformation\n",
    "    mask_rank = tf.rank(tertiary_mask).numpy()\n",
    "    mask_padding = tf.repeat(padding, mask_rank, axis=0)\n",
    "    tertiary_mask = tf.pad(tertiary_mask, mask_padding, constant_values=0)\n",
    "    \n",
    "    # perform crop\n",
    "    if total_crops > 0:\n",
    "        batches = create_protein_batches(primary, tertiary, tertiary_mask, stride)\n",
    "        # transform teritiary to distogram\n",
    "        for i in range(len(batches)):\n",
    "            dist_tertiary = to_distogram(batches[i][1], min_val=minimum_bin_val, max_val=maximum_bin_val, num_bins=num_bins)\n",
    "            dist_tertiary = tf.convert_to_tensor(dist_tertiary, dtype=tertiary.dtype)\n",
    "            dist_tertiary = K.cast_to_floatx(dist_tertiary)\n",
    "            batches[i] = (batches[i][0], dist_tertiary, batches[i][2])\n",
    "        return batches\n",
    "    else:\n",
    "        tertiary = to_distogram(tertiary, min_val=minimum_bin_val, max_val=maximum_bin_val, num_bins=num_bins)\n",
    "        tertiary = tf.convert_to_tensor(tertiary, dtype=tertiary.dtype)\n",
    "        tertiary = K.cast_to_floatx(tertiary)\n",
    "        return ([(primary, tertiary, tertiary_mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset_test(file_paths, parameters):\n",
    "    \"\"\"\n",
    "    This function iterates over all input files\n",
    "    and extract record information from each single file\n",
    "    Use Yield for optimization purpose causes reading when needed\n",
    "    \"\"\"\n",
    "#     print(type(parameters))\n",
    "    if isinstance(parameters, np.ndarray):\n",
    "        li = parameters.tolist()\n",
    "        parameters = {item[0].decode('ascii'): float(item[1]) for item in li}\n",
    "#     print(parameters)\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_paths)\n",
    "    for data in raw_dataset:\n",
    "        primary, evolutionary, tertiary, ter_mask = parse_tfexample(data)\n",
    "        transformed_batch = [(primary, tertiary, ter_mask)]\n",
    "#         transformed_batch = generator_transform(primary, evolutionary, tertiary, ter_mask, \n",
    "#                                                 stride=parameters[\"stride\"], \n",
    "#                                                 padding_value=parameters[\"padding_value\"], \n",
    "#                                                 minimum_bin_val=parameters[\"minimum_bin_val\"], \n",
    "#                                                 maximum_bin_val=parameters[\"maximum_bin_val\"], \n",
    "#                                                 num_bins=parameters[\"num_bins\"])\n",
    "        for subset in transformed_batch:\n",
    "            yield subset # has values (primary, tertiary, tertiary mask)\n",
    "#         if primary.shape[0]>64:\n",
    "#             yield (primary, evolutionary, tertiary, ter_mask)\n",
    "#         else:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../proteinnet/data/casp7/training/100/13',\n",
       " '../proteinnet/data/casp7/training/100/16',\n",
       " '../proteinnet/data/casp7/training/100/41',\n",
       " '../proteinnet/data/casp7/training/100/9',\n",
       " '../proteinnet/data/casp7/training/100/6',\n",
       " '../proteinnet/data/casp7/training/100/115',\n",
       " '../proteinnet/data/casp7/training/100/40',\n",
       " '../proteinnet/data/casp7/training/100/104',\n",
       " '../proteinnet/data/casp7/training/100/33',\n",
       " '../proteinnet/data/casp7/training/100/22',\n",
       " '../proteinnet/data/casp7/training/100/93',\n",
       " '../proteinnet/data/casp7/training/100/54',\n",
       " '../proteinnet/data/casp7/training/100/61',\n",
       " '../proteinnet/data/casp7/training/100/105',\n",
       " '../proteinnet/data/casp7/training/100/109',\n",
       " '../proteinnet/data/casp7/training/100/92',\n",
       " '../proteinnet/data/casp7/training/100/38',\n",
       " '../proteinnet/data/casp7/training/100/2',\n",
       " '../proteinnet/data/casp7/training/100/4',\n",
       " '../proteinnet/data/casp7/training/100/112',\n",
       " '../proteinnet/data/casp7/training/100/24',\n",
       " '../proteinnet/data/casp7/training/100/116',\n",
       " '../proteinnet/data/casp7/training/100/52',\n",
       " '../proteinnet/data/casp7/training/100/129',\n",
       " '../proteinnet/data/casp7/training/100/99',\n",
       " '../proteinnet/data/casp7/training/100/25',\n",
       " '../proteinnet/data/casp7/training/100/135',\n",
       " '../proteinnet/data/casp7/training/100/88',\n",
       " '../proteinnet/data/casp7/training/100/69',\n",
       " '../proteinnet/data/casp7/training/100/5',\n",
       " '../proteinnet/data/casp7/training/100/84',\n",
       " '../proteinnet/data/casp7/training/100/35',\n",
       " '../proteinnet/data/casp7/training/100/76',\n",
       " '../proteinnet/data/casp7/training/100/60',\n",
       " '../proteinnet/data/casp7/training/100/15',\n",
       " '../proteinnet/data/casp7/training/100/49',\n",
       " '../proteinnet/data/casp7/training/100/103',\n",
       " '../proteinnet/data/casp7/training/100/67',\n",
       " '../proteinnet/data/casp7/training/100/132',\n",
       " '../proteinnet/data/casp7/training/100/43',\n",
       " '../proteinnet/data/casp7/training/100/28',\n",
       " '../proteinnet/data/casp7/training/100/101',\n",
       " '../proteinnet/data/casp7/training/100/20',\n",
       " '../proteinnet/data/casp7/training/100/79',\n",
       " '../proteinnet/data/casp7/training/100/68',\n",
       " '../proteinnet/data/casp7/training/100/95',\n",
       " '../proteinnet/data/casp7/training/100/17',\n",
       " '../proteinnet/data/casp7/training/100/53',\n",
       " '../proteinnet/data/casp7/training/100/119',\n",
       " '../proteinnet/data/casp7/training/100/18',\n",
       " '../proteinnet/data/casp7/training/100/64',\n",
       " '../proteinnet/data/casp7/training/100/50',\n",
       " '../proteinnet/data/casp7/training/100/120',\n",
       " '../proteinnet/data/casp7/training/100/83',\n",
       " '../proteinnet/data/casp7/training/100/113',\n",
       " '../proteinnet/data/casp7/training/100/127',\n",
       " '../proteinnet/data/casp7/training/100/29',\n",
       " '../proteinnet/data/casp7/training/100/46',\n",
       " '../proteinnet/data/casp7/training/100/73',\n",
       " '../proteinnet/data/casp7/training/100/66',\n",
       " '../proteinnet/data/casp7/training/100/45',\n",
       " '../proteinnet/data/casp7/training/100/14',\n",
       " '../proteinnet/data/casp7/training/100/59',\n",
       " '../proteinnet/data/casp7/training/100/123',\n",
       " '../proteinnet/data/casp7/training/100/63',\n",
       " '../proteinnet/data/casp7/training/100/102',\n",
       " '../proteinnet/data/casp7/training/100/39',\n",
       " '../proteinnet/data/casp7/training/100/130',\n",
       " '../proteinnet/data/casp7/training/100/134',\n",
       " '../proteinnet/data/casp7/training/100/80',\n",
       " '../proteinnet/data/casp7/training/100/55',\n",
       " '../proteinnet/data/casp7/training/100/56',\n",
       " '../proteinnet/data/casp7/training/100/8',\n",
       " '../proteinnet/data/casp7/training/100/108',\n",
       " '../proteinnet/data/casp7/training/100/111',\n",
       " '../proteinnet/data/casp7/training/100/44',\n",
       " '../proteinnet/data/casp7/training/100/27',\n",
       " '../proteinnet/data/casp7/training/100/19',\n",
       " '../proteinnet/data/casp7/training/100/37',\n",
       " '../proteinnet/data/casp7/training/100/86',\n",
       " '../proteinnet/data/casp7/training/100/7',\n",
       " '../proteinnet/data/casp7/training/100/118',\n",
       " '../proteinnet/data/casp7/training/100/122',\n",
       " '../proteinnet/data/casp7/training/100/12',\n",
       " '../proteinnet/data/casp7/training/100/58',\n",
       " '../proteinnet/data/casp7/training/100/62',\n",
       " '../proteinnet/data/casp7/training/100/71',\n",
       " '../proteinnet/data/casp7/training/100/23',\n",
       " '../proteinnet/data/casp7/training/100/78',\n",
       " '../proteinnet/data/casp7/training/100/96',\n",
       " '../proteinnet/data/casp7/training/100/131',\n",
       " '../proteinnet/data/casp7/training/100/48',\n",
       " '../proteinnet/data/casp7/training/100/87',\n",
       " '../proteinnet/data/casp7/training/100/82',\n",
       " '../proteinnet/data/casp7/training/100/85',\n",
       " '../proteinnet/data/casp7/training/100/89',\n",
       " '../proteinnet/data/casp7/training/100/31',\n",
       " '../proteinnet/data/casp7/training/100/91',\n",
       " '../proteinnet/data/casp7/training/100/34',\n",
       " '../proteinnet/data/casp7/training/100/70',\n",
       " '../proteinnet/data/casp7/training/100/30',\n",
       " '../proteinnet/data/casp7/training/100/128',\n",
       " '../proteinnet/data/casp7/training/100/125',\n",
       " '../proteinnet/data/casp7/training/100/1',\n",
       " '../proteinnet/data/casp7/training/100/110',\n",
       " '../proteinnet/data/casp7/training/100/36',\n",
       " '../proteinnet/data/casp7/training/100/75',\n",
       " '../proteinnet/data/casp7/training/100/11',\n",
       " '../proteinnet/data/casp7/training/100/21',\n",
       " '../proteinnet/data/casp7/training/100/107',\n",
       " '../proteinnet/data/casp7/training/100/51',\n",
       " '../proteinnet/data/casp7/training/100/57',\n",
       " '../proteinnet/data/casp7/training/100/10',\n",
       " '../proteinnet/data/casp7/training/100/90',\n",
       " '../proteinnet/data/casp7/training/100/133',\n",
       " '../proteinnet/data/casp7/training/100/98',\n",
       " '../proteinnet/data/casp7/training/100/94',\n",
       " '../proteinnet/data/casp7/training/100/117',\n",
       " '../proteinnet/data/casp7/training/100/126',\n",
       " '../proteinnet/data/casp7/training/100/121',\n",
       " '../proteinnet/data/casp7/training/100/26',\n",
       " '../proteinnet/data/casp7/training/100/74',\n",
       " '../proteinnet/data/casp7/training/100/81',\n",
       " '../proteinnet/data/casp7/training/100/42',\n",
       " '../proteinnet/data/casp7/training/100/106',\n",
       " '../proteinnet/data/casp7/training/100/3',\n",
       " '../proteinnet/data/casp7/training/100/97',\n",
       " '../proteinnet/data/casp7/training/100/32',\n",
       " '../proteinnet/data/casp7/training/100/77',\n",
       " '../proteinnet/data/casp7/training/100/47',\n",
       " '../proteinnet/data/casp7/training/100/114',\n",
       " '../proteinnet/data/casp7/training/100/124',\n",
       " '../proteinnet/data/casp7/training/100/100',\n",
       " '../proteinnet/data/casp7/training/100/72',\n",
       " '../proteinnet/data/casp7/training/100/65']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = glob.glob(\"../proteinnet/data/casp7/training/100/*\")\n",
    "params = {\n",
    "    \"stride\": 64,\n",
    "    \"padding_value\": -1,\n",
    "    \"minimum_bin_val\": 2,\n",
    "    \"maximum_bin_val\": 22,\n",
    "    \"num_bins\": 64\n",
    "}\n",
    "items = []\n",
    "for i,j in params.items():\n",
    "    items.append([i, j])\n",
    "path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_counter = tf.data.Dataset.from_generator(parse_dataset_test, args=[path, np.array(items)], output_types=(tf.float32, tf.float32, tf.float32),output_shapes= ((None, ),(None, None, ),(None, None, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34557"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for _ in ds_counter:\n",
    "    count +=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-cuda8",
   "language": "python",
   "name": "tf-gpu-cuda8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
